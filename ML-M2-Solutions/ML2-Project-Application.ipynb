{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973b50ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# ML2 - Project - Traffic Sign Detection - Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee6bbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Self driving cars are becoming more prevalent in our world today. The technology behind self driving cars is very complicated because it relies on various components such as sensors, cameras and machine learning models. Every field is important but the core element is the machine learning algorithm. The ML algortithm needs to detect traffic signs, pedestrians, traffic lights, road lines and other vehicles in order to properly navigate the road. The closer the accuracy of a model is to 100% the more suitable and safe it is for use.\n",
    "<img style=\"float: center; /\"  width = \"1000\"  src=\"Notebook Images/ML-M2-Project-Image1.png\">\n",
    "\n",
    "## Your task is to build an application that can detect and annotate traffic signs from a video input. \n",
    "## The following are the 43 classes of traffic signs:\n",
    "<img style=\"float: center; /\"  width = \"1000\"  src=\"Notebook Images/ML-M2-Project-Image2.png\">\n",
    "\n",
    "## What you need to do:\n",
    "1. Load the pretrained model\n",
    "2. Define a function to annotate\n",
    "3. Define a function to perform the sliding window\n",
    "4. Create the GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137d33a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": 1
   },
   "source": [
    "### 1. Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3233aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_model(\"trafficlightmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872c521",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": 2
   },
   "source": [
    "### 2. Define a function to perform the detection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f5f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSign(img):\n",
    "    # Get the contours of the image\n",
    "    contours = find_contours(img) \n",
    "    # For each contour, get the rectangle\n",
    "    rects = get_boundingbox(img, contours)\n",
    "    for rect in rects:\n",
    "        size = max(rect[2], rect[3])\n",
    "        x1 = rect[0]\n",
    "        y1 = rect[1]\n",
    "        x2 =  x1 + rect[2]\n",
    "        y2 =  y1 + rect[3]\n",
    "        \n",
    "        # Crop the image at each contour\n",
    "        crop_img = crop_image(img, x1, y1, x2, y2)\n",
    "        \n",
    "        # Predict the cropped image using the given model\n",
    "        name , probabilityValue = predict_sign(model, crop_img)\n",
    "        # If the result predicts a sign, then draw a square at the contour and label it\n",
    "        if probabilityValue > 0.90 and name != \"Background\":\n",
    "            draw_rectangle(img, x1, y1, x2, y2)\n",
    "            put_text(img, x1, y1-10, name)\n",
    "            put_text(img, x1, y1-40,str(round(probabilityValue * 100, 2)))\n",
    "    \n",
    "    # return the image   \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4393706",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": 3
   },
   "source": [
    "### 3.  Create the GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb58ea6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "3.1 Create the elements of the GUI and test the interface. Link the \"Annotate\" button to the __*loadAntVid*__ function. Use the sample video \"sample_video.mp4\" to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "634e2a6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c0f5ef208a4e5d9e6d945594a9cb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Box(children=(VBox(children=(HTML(value=' <h1 style=\"text-align:center; font-size:30pt; color:bl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 131/594 [00:28<01:44,  4.42it/s]"
     ]
    }
   ],
   "source": [
    "main = start_layout(\"30%\", \"50%\", \"20%\")\n",
    "title = create_title_text(description = \"Traffic Sign Detection\", size = \"30pt\", height = \"70%\")\n",
    "upload2 = create_fileUploadButton(description = \"Upload Video\", height = \"90%\")\n",
    "button6 = create_button(description = 'Annotate Video', height = \"90%\", button_color = \"white\")\n",
    "link_button(button6, loadAntVid, main, detectSign)\n",
    "place_elements(main, title, location = \"header\")\n",
    "place_elements(main, upload2, button6, location = \"header\", alignment = \"Horizontal\")\n",
    "display_main(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
